{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"About the Scripta Compiler (( This document is very much a work in progress. )) The Scripta compiler translates source text written in a markup language to an Elm representation of Html. The markup languages supported are L0 microLaTeX XMarkdown The compiler provides interactive, real-time editing with error recovery for these languages. See the introductin and overview for more information. See also this conference talk at Lambda Days for an outline of the error recovery strategy. For a very simple use of the Scripta compiler without error recovery, see Scripta-example1 . For its use in a real web app (with error recovery), see Scripta.io . Here is documentation for both apps as well as Scripta Desktop . This project has been partially supported by the Simons Foundation. We thank them for their generosity. Contact: James Carlson jxxcarlson at gmail @jxxcarlson on the Elm Slack @epsilon2718 on Twitter","title":"Home"},{"location":"#about-the-scripta-compiler","text":"(( This document is very much a work in progress. )) The Scripta compiler translates source text written in a markup language to an Elm representation of Html. The markup languages supported are L0 microLaTeX XMarkdown The compiler provides interactive, real-time editing with error recovery for these languages. See the introductin and overview for more information. See also this conference talk at Lambda Days for an outline of the error recovery strategy. For a very simple use of the Scripta compiler without error recovery, see Scripta-example1 . For its use in a real web app (with error recovery), see Scripta.io . Here is documentation for both apps as well as Scripta Desktop . This project has been partially supported by the Simons Foundation. We thank them for their generosity. Contact: James Carlson jxxcarlson at gmail @jxxcarlson on the Elm Slack @epsilon2718 on Twitter","title":"About the Scripta Compiler"},{"location":"common-code/","text":"Common Code Functional loops Functional loops are used throughout the compiler, and in particular in the L0 parser. The key element of such a loop is a driver function f : state -> Step state a that does some computation on the state and returns either a value of type Done a or a value of type Loop state . In the first case the loop terminates with the indicated value. In the second case it runs again with the new state value.\u02dc -- Parser.Helpers type Step state a = Loop state | Done a loop : state -> (state -> Step state a) -> a loop s f = case f s of Loop s_ -> loop s_ f Done b -> b","title":"Common code"},{"location":"common-code/#common-code","text":"","title":"Common Code"},{"location":"common-code/#functional-loops","text":"Functional loops are used throughout the compiler, and in particular in the L0 parser. The key element of such a loop is a driver function f : state -> Step state a that does some computation on the state and returns either a value of type Done a or a value of type Loop state . In the first case the loop terminates with the indicated value. In the second case it runs again with the new state value.\u02dc -- Parser.Helpers type Step state a = Loop state | Done a loop : state -> (state -> Step state a) -> a loop s f = case f s of Loop s_ -> loop s_ f Done b -> b","title":"Functional loops"},{"location":"dataStructures/","text":"Data Structures The primary data structures of the parser are Primitive Blocks ( PrimitiveBlock ) Expressions ( Expr ) Expression blocks ( ExpressionBlock ) Accumulator ( Accumlator ) The parser first breaks source text into primitive blocks (1), then maps the internal language parser over a list of primitive blocks to produce expression blocks (2). Primitive Blocks Blocks have the rather elaborate type listed below. This complex structure is necessary for interactive real-time editing with error recovery. By real-time we mean that the rendered text is updated \"instantaneously\" in the browser as the user types in text. By interactive, we mean (for example) that click on the rendered text brings the associated source text into view while simultaneously highlighting it. In addition, if the user selects a block of source text and presses ctrl-S (S for 'sync'), the corresponding rendered text is brought into view and highlighted. In the case of L0 and XMarkdown, a primitive block is defined by type alias PrimitiveBlock = { indent : Int , lineNumber : Int , position : Int , content : List String , name : Maybe String , args : List String , properties : Dict String String , sourceText : String , blockType : PrimitiveBlockType , error : Maybe { error : String } } In the case of MicroLaTeX, there are two additional fields, level: Int and status: Status . Expressions -- Parser.Expr type Expr = Fun String (List Expr) Meta | Text String Meta | Verbatim String String Meta Expression Blocks -- Parser.Block type ExpressionBlock = ExpressionBlock { name : Maybe String , args : List String , properties : Dict String String , indent : Int , lineNumber : Int , numberOfLines : Int , id : String , tag : String , blockType : BlockType , content : Either String (List Expr) , messages : List String , sourceText : String , error : Maybe { error : String } } Edit records -- Compiler.AbstractDifferentialCompiler type alias EditRecord chunk parsedChunk accumulator = { chunks : List chunk , parsed : List parsedChunk , tree : List (Tree parsedChunk) , accumulator : accumulator , lang : Language , messages : List String , initialData : InitialData } Accumulator The Accumulator type, defined in module Compiler.Acc , is used to collect, build up, and apply auxiliary information about the text. For example, the headingIndex stores the current section number, where \"current\" refers to the the current section of the document as the accumulator-building function walks through the current parse forest. As it does, it simultaneously (1) updates the accumulator and (2) applies new \"patches\" of the accumulator to the parse forest. This process is managed by function transformAccumulateTree which is called every time the parser pipeline runs. For this reason one does not have to recompile to have up-to-date cross-references, etc., as in standard LaTeX. transformAccumulateTree : Tree ExpressionBlock -> Accumulator -> ( Accumulator, Tree ExpressionBlock ) transformAccumulateTree tree acc = Tree.mapAccumulate transformAccumulateBlock acc tree where the function transformAccumulateBlock carries out the per-block step: transformAccumulateBlock : Accumulator -> ExpressionBlock -> ( Accumulator, ExpressionBlock ) This function in turn calls upon functions updateAccumulator for (1) and function transformBlock for (2): updateAccumulator : ExpressionBlock -> Accumulator -> Accumulator transformBlock : Accumulator -> ExpressionBlock -> ExpressionBlock -- Compiler.Acc type alias Accumulator = { language : Language , headingIndex : Vector , documentIndex : Vector , counter : Dict String Int , blockCounter : Int , itemVector : Vector -- Used for section numbering , numberedItemDict : Dict String { level : Int, index : Int } , numberedBlockNames : List String , inList : Bool , reference : Dict String { id : String, numRef : String } , terms : Dict String TermLoc , footnotes : Dict String TermLoc , footnoteNumbers : Dict String Int , mathMacroDict : Parser.MathMacro.MathMacroDict , textMacroDict : Dict String Macro , keyValueDict : Dict String String , qAndAList : List ( String, String ) , qAndADict : Dict String String }","title":"Data structures"},{"location":"dataStructures/#data-structures","text":"The primary data structures of the parser are Primitive Blocks ( PrimitiveBlock ) Expressions ( Expr ) Expression blocks ( ExpressionBlock ) Accumulator ( Accumlator ) The parser first breaks source text into primitive blocks (1), then maps the internal language parser over a list of primitive blocks to produce expression blocks (2).","title":"Data Structures"},{"location":"dataStructures/#primitive-blocks","text":"Blocks have the rather elaborate type listed below. This complex structure is necessary for interactive real-time editing with error recovery. By real-time we mean that the rendered text is updated \"instantaneously\" in the browser as the user types in text. By interactive, we mean (for example) that click on the rendered text brings the associated source text into view while simultaneously highlighting it. In addition, if the user selects a block of source text and presses ctrl-S (S for 'sync'), the corresponding rendered text is brought into view and highlighted. In the case of L0 and XMarkdown, a primitive block is defined by type alias PrimitiveBlock = { indent : Int , lineNumber : Int , position : Int , content : List String , name : Maybe String , args : List String , properties : Dict String String , sourceText : String , blockType : PrimitiveBlockType , error : Maybe { error : String } } In the case of MicroLaTeX, there are two additional fields, level: Int and status: Status .","title":"Primitive Blocks"},{"location":"dataStructures/#expressions","text":"-- Parser.Expr type Expr = Fun String (List Expr) Meta | Text String Meta | Verbatim String String Meta","title":"Expressions"},{"location":"dataStructures/#expression-blocks","text":"-- Parser.Block type ExpressionBlock = ExpressionBlock { name : Maybe String , args : List String , properties : Dict String String , indent : Int , lineNumber : Int , numberOfLines : Int , id : String , tag : String , blockType : BlockType , content : Either String (List Expr) , messages : List String , sourceText : String , error : Maybe { error : String } }","title":"Expression Blocks"},{"location":"dataStructures/#edit-records","text":"-- Compiler.AbstractDifferentialCompiler type alias EditRecord chunk parsedChunk accumulator = { chunks : List chunk , parsed : List parsedChunk , tree : List (Tree parsedChunk) , accumulator : accumulator , lang : Language , messages : List String , initialData : InitialData }","title":"Edit records"},{"location":"dataStructures/#accumulator","text":"The Accumulator type, defined in module Compiler.Acc , is used to collect, build up, and apply auxiliary information about the text. For example, the headingIndex stores the current section number, where \"current\" refers to the the current section of the document as the accumulator-building function walks through the current parse forest. As it does, it simultaneously (1) updates the accumulator and (2) applies new \"patches\" of the accumulator to the parse forest. This process is managed by function transformAccumulateTree which is called every time the parser pipeline runs. For this reason one does not have to recompile to have up-to-date cross-references, etc., as in standard LaTeX. transformAccumulateTree : Tree ExpressionBlock -> Accumulator -> ( Accumulator, Tree ExpressionBlock ) transformAccumulateTree tree acc = Tree.mapAccumulate transformAccumulateBlock acc tree where the function transformAccumulateBlock carries out the per-block step: transformAccumulateBlock : Accumulator -> ExpressionBlock -> ( Accumulator, ExpressionBlock ) This function in turn calls upon functions updateAccumulator for (1) and function transformBlock for (2): updateAccumulator : ExpressionBlock -> Accumulator -> Accumulator transformBlock : Accumulator -> ExpressionBlock -> ExpressionBlock -- Compiler.Acc type alias Accumulator = { language : Language , headingIndex : Vector , documentIndex : Vector , counter : Dict String Int , blockCounter : Int , itemVector : Vector -- Used for section numbering , numberedItemDict : Dict String { level : Int, index : Int } , numberedBlockNames : List String , inList : Bool , reference : Dict String { id : String, numRef : String } , terms : Dict String TermLoc , footnotes : Dict String TermLoc , footnoteNumbers : Dict String Int , mathMacroDict : Parser.MathMacro.MathMacroDict , textMacroDict : Dict String Macro , keyValueDict : Dict String String , qAndAList : List ( String, String ) , qAndADict : Dict String String }","title":"Accumulator"},{"location":"differential-parser/","text":"Differential Parser Differential parsing is an optimization used to speed up recompilation of large inputs. Since parsing is the most expensive part of the compiler pipeline, the idea is to only re-parse what has been changed after an edit. Differ We use an extremely primitive strategy. Let u and v be two lists of things of type q . Write them as u = axb, v = ayb, where a is the greatest common prefix and b is the greatest common suffix. Return DiffRecord a b x y. This operation is carried out by -- Compiler.Differ diff : List p -> List p -> DiffRecord p where -- Compiler.Differ type alias DiffRecord p = { commonPrefix : List p , commonSuffix : List p , middleSegmentInSource : List p , middleSegmentInTarget : List p } A DiffRecord can be used to transform a list using function differentialTransform and a function transform: p -> q . -- Compiler.Differ differentialTransform : (p -> q) -> DiffRecord p -> List q -> List q DifferForest Module Compiler.DifferForest is designed to diff lists with an implicit forest structure (list of trees) defined by a function level: p -> Int . In the resulting DiffRecord , the prefix, suffix, and middle segments all represent subforests. To illustrate the main issue, consider the lists u and v (below). These have an indentation structure like an outline for an article, and so define the structure of a forest. In the example below, the leaf jkl in the tree with root def is changed to JKL . u: ---- abc def ghi jkl mno pqr v: ---- abc def ghi JKL mno pqr In this example the diff record represents the following structure: commonPrefix: ---- abc middleSegmentInSource: --- def ghi jkl mno middleSegmentInTarget: --- def ghi JKL mno commonSuffix: --- pqr","title":"Differential Parser"},{"location":"differential-parser/#differential-parser","text":"Differential parsing is an optimization used to speed up recompilation of large inputs. Since parsing is the most expensive part of the compiler pipeline, the idea is to only re-parse what has been changed after an edit.","title":"Differential Parser"},{"location":"differential-parser/#differ","text":"We use an extremely primitive strategy. Let u and v be two lists of things of type q . Write them as u = axb, v = ayb, where a is the greatest common prefix and b is the greatest common suffix. Return DiffRecord a b x y. This operation is carried out by -- Compiler.Differ diff : List p -> List p -> DiffRecord p where -- Compiler.Differ type alias DiffRecord p = { commonPrefix : List p , commonSuffix : List p , middleSegmentInSource : List p , middleSegmentInTarget : List p } A DiffRecord can be used to transform a list using function differentialTransform and a function transform: p -> q . -- Compiler.Differ differentialTransform : (p -> q) -> DiffRecord p -> List q -> List q","title":"Differ"},{"location":"differential-parser/#differforest","text":"Module Compiler.DifferForest is designed to diff lists with an implicit forest structure (list of trees) defined by a function level: p -> Int . In the resulting DiffRecord , the prefix, suffix, and middle segments all represent subforests. To illustrate the main issue, consider the lists u and v (below). These have an indentation structure like an outline for an article, and so define the structure of a forest. In the example below, the leaf jkl in the tree with root def is changed to JKL . u: ---- abc def ghi jkl mno pqr v: ---- abc def ghi JKL mno pqr In this example the diff record represents the following structure: commonPrefix: ---- abc middleSegmentInSource: --- def ghi jkl mno middleSegmentInTarget: --- def ghi JKL mno commonSuffix: --- pqr","title":"DifferForest"},{"location":"introduction/","text":"Introduction The Scripta compiler translates source text written in a markup language to an Elm representation of Html. Markup Languages The languages supported by Scripta are L0 microLaTeX XMarkdown Blocks The text of these markup languages should be thought of as structured into blocks, the content of which is written in an internal language . For example, in microLaTeX, one might have the text below. There are seven blocks, each of which is separated from its neighbor by an empty line. The first block is a paragraph; its content consists of plain text followed by the TeX macro expression \\italic{prime} followed by more plain text. Let's talk about \\italic{prime} numbers. \\begin{theorem} There are infinitely many primes $p$, and in fact there are infinitely many primes \\begin{equation} p \\equiv 1 \\ \\text{mod}\\ 4 \\end{equation} and also \\begin{equation} p \\equiv 1 \\ \\text{mod}\\ 8 \\end{equation} and so on. \\end{theorem} The first paragraph of the theorem was known to Euclid. The body of the theorem block consists of six blocks \u2014 the three paragraph blocks Let's talk ... , and also , and and so on . There also the two equation blocks. The blocks in the body of the theorem block constitute the \\italic{children} of the block. It is the job of the parser to (1) discover the forest structure, and (2) to parse the content of the blocks. Note that we can visualize the block structure as an outline, as below. PARAGRAPH THEOREM PARAGRPH EQUATION EQUATION PARAGRAPH PARAGRAM In some languages, e.g. L0 and Markdown, the block structure is literally given by the \"outline\" structure, that is, by indentation. Below is our example rewritten in L0: Let's talk about [italic prime] numbers. | theorem There are infinitely many primes $p$, and in fact there are infinitely many primes || equation p \\equiv 1 \\ \\text{mod}\\ 4 and also || equation p \\equiv 1 \\ \\text{mod}\\ 8 and so on. The first paragraph of the theorem was known to Euclid. Note that an outline is fully equivalent to a tree: |-- PARAGRAPH |-- THEOREM |- PARAGRAPH |- EQUATION |- EQUATION |- PARAGRAPH |- PARAGRAPH Internal Language While the surface syntax in L0, microLaTeX and XMarkdown depends on the language, the abstract syntax is the same for all tree. Indeed, text in the internal language always parses to Either String (List Expr) , where type Expr = Fun String (List Expr) Meta | Text String Meta | Verbatim String String Meta Block Definition In the case of L0 and XMarkdown, a primitive block is defined by type alias PrimitiveBlock = { indent : Int , lineNumber : Int , position : Int , content : List String , name : Maybe String , args : List String , properties : Dict String String , sourceText : String , blockType : PrimitiveBlockType , error : Maybe { error : String } } In the case of MicroLaTeX, there are two additional fields, level: Int and status: Status .","title":"Introduction"},{"location":"introduction/#introduction","text":"The Scripta compiler translates source text written in a markup language to an Elm representation of Html.","title":"Introduction"},{"location":"introduction/#markup-languages","text":"The languages supported by Scripta are L0 microLaTeX XMarkdown","title":"Markup Languages"},{"location":"introduction/#blocks","text":"The text of these markup languages should be thought of as structured into blocks, the content of which is written in an internal language . For example, in microLaTeX, one might have the text below. There are seven blocks, each of which is separated from its neighbor by an empty line. The first block is a paragraph; its content consists of plain text followed by the TeX macro expression \\italic{prime} followed by more plain text. Let's talk about \\italic{prime} numbers. \\begin{theorem} There are infinitely many primes $p$, and in fact there are infinitely many primes \\begin{equation} p \\equiv 1 \\ \\text{mod}\\ 4 \\end{equation} and also \\begin{equation} p \\equiv 1 \\ \\text{mod}\\ 8 \\end{equation} and so on. \\end{theorem} The first paragraph of the theorem was known to Euclid. The body of the theorem block consists of six blocks \u2014 the three paragraph blocks Let's talk ... , and also , and and so on . There also the two equation blocks. The blocks in the body of the theorem block constitute the \\italic{children} of the block. It is the job of the parser to (1) discover the forest structure, and (2) to parse the content of the blocks. Note that we can visualize the block structure as an outline, as below. PARAGRAPH THEOREM PARAGRPH EQUATION EQUATION PARAGRAPH PARAGRAM In some languages, e.g. L0 and Markdown, the block structure is literally given by the \"outline\" structure, that is, by indentation. Below is our example rewritten in L0: Let's talk about [italic prime] numbers. | theorem There are infinitely many primes $p$, and in fact there are infinitely many primes || equation p \\equiv 1 \\ \\text{mod}\\ 4 and also || equation p \\equiv 1 \\ \\text{mod}\\ 8 and so on. The first paragraph of the theorem was known to Euclid. Note that an outline is fully equivalent to a tree: |-- PARAGRAPH |-- THEOREM |- PARAGRAPH |- EQUATION |- EQUATION |- PARAGRAPH |- PARAGRAPH","title":"Blocks"},{"location":"introduction/#internal-language","text":"While the surface syntax in L0, microLaTeX and XMarkdown depends on the language, the abstract syntax is the same for all tree. Indeed, text in the internal language always parses to Either String (List Expr) , where type Expr = Fun String (List Expr) Meta | Text String Meta | Verbatim String String Meta","title":"Internal Language"},{"location":"introduction/#block-definition","text":"In the case of L0 and XMarkdown, a primitive block is defined by type alias PrimitiveBlock = { indent : Int , lineNumber : Int , position : Int , content : List String , name : Maybe String , args : List String , properties : Dict String String , sourceText : String , blockType : PrimitiveBlockType , error : Maybe { error : String } } In the case of MicroLaTeX, there are two additional fields, level: Int and status: Status .","title":"Block Definition"},{"location":"l0-parser/","text":"The L0 Parser (( Under construction! )) Parser The parser is implemented as a functional loop with state defined by -- L0.Parser.Expression type alias State = { step : Int , tokens : List Token , numberOfTokens : Int , tokenIndex : Int , committed : List Expr , stack : List Token , messages : List String , lineNumber : Int } and driving function State -> Step State State defined by -- L0.Parser.Expression nextStep : State -> Step State State nextStep state = case getToken state of Nothing -> if stackIsEmpty state then Done state else recoverFromError state Just token -> state |> advanceTokenIndex |> pushOrCommit token |> reduceState |> (\\st -> { st | step = st.step + 1 }) |> Loop The reduceState function asks whether the stack is reducible using the function isReducible discussed below. If it is, it reduces the stack using reduceStack , returning the updated state. If not, the state is passed on unchanged. -- L0.Parser.Expression reduceState : State -> State reduceState state = if tokensAreReducible state then { state | stack = [], committed = reduceStack state ++ state.committed } else state Reducibility -- L0.Parser.Match: isReducible : List Symbol -> Bool isReducible symbols_ = let symbols = List.filter (\\sym -> sym /= WS) symbols_ in case symbols of M :: rest -> List.head (List.reverse rest) == Just M C :: rest -> List.head (List.reverse rest) == Just C L :: ST :: rest -> case List.head (List.reverse rest) of Just R -> hasReducibleArgs (dropLast rest) _ -> False _ -> False","title":"L0 Parser"},{"location":"l0-parser/#the-l0-parser","text":"(( Under construction! ))","title":"The L0 Parser"},{"location":"l0-parser/#parser","text":"The parser is implemented as a functional loop with state defined by -- L0.Parser.Expression type alias State = { step : Int , tokens : List Token , numberOfTokens : Int , tokenIndex : Int , committed : List Expr , stack : List Token , messages : List String , lineNumber : Int } and driving function State -> Step State State defined by -- L0.Parser.Expression nextStep : State -> Step State State nextStep state = case getToken state of Nothing -> if stackIsEmpty state then Done state else recoverFromError state Just token -> state |> advanceTokenIndex |> pushOrCommit token |> reduceState |> (\\st -> { st | step = st.step + 1 }) |> Loop The reduceState function asks whether the stack is reducible using the function isReducible discussed below. If it is, it reduces the stack using reduceStack , returning the updated state. If not, the state is passed on unchanged. -- L0.Parser.Expression reduceState : State -> State reduceState state = if tokensAreReducible state then { state | stack = [], committed = reduceStack state ++ state.committed } else state","title":"Parser"},{"location":"l0-parser/#reducibility","text":"-- L0.Parser.Match: isReducible : List Symbol -> Bool isReducible symbols_ = let symbols = List.filter (\\sym -> sym /= WS) symbols_ in case symbols of M :: rest -> List.head (List.reverse rest) == Just M C :: rest -> List.head (List.reverse rest) == Just C L :: ST :: rest -> case List.head (List.reverse rest) of Just R -> hasReducibleArgs (dropLast rest) _ -> False _ -> False","title":"Reducibility"},{"location":"lx-parser/","text":"MicroLaTeX Parser The MicroLaTeX parser first transforms source into a list of primitive LaTeX blocks, then by mapping the parser for the internal language over this list, into a list of expression blocks. Primitive Blocks A primitve LaTeX block is a 13-field record as displayed below. -- Parser.PrimitiveLaTeXBlock type alias PrimitiveLaTeXBlock = { indent : Int , lineNumber : Int , position : Int , level : Int , content : List String , firstLine : String , name : Maybe String , args : List String , properties : Dict String String , sourceText : String , blockType : PrimitiveBlockType , status : Status , error : Maybe PrimitiveBlockError } When the source text is parsed into a list of blocks, it is grouped into lists of strings in the content field. The content is also stored as a string in the sourceText field. This is to facilitate synchronization of source text and rendered text. The source text field is carried into the final syntax tree (forest of expression blocks). Consequently, if a piece source text is selected, the syntax tree can can be searched, the matching element can be located and then used to highlight the corresponding part of the rendered text. The indent field is the number of spaces of indentation of the first line of the block; lineNumber is the line number of the first line of the text in the source string; position is its character position in that string. The level field is the depth of the block in the eventual tree structure. Blocks may be un-named, as in the case of paragraph, or named, in the case of a LaTeX environment. This information is stored in the name field. For example, the name of the block \\begin{theorem} ... \\end{theorem} is Just \"theorem\" The firstline field is the first line of a block, i.e., its header. If the header of a block is \"\\begin{theorem}[Pythagoras]\", then its name is \"theorem\" and args is the list [\"Pythagoras] . If we had \"\\begin{theorem}[Pythagoras, foo:bar]\" (XX) then args is still [\"Pythagoras\"], and properties is a dictionary with one key, \"foo\", whose value is \"bar\". Thus args is a list of unnamed args and properties is a dictionary of key-value pairs derived from the named args. (XX: improve this discussion) The blockType field has type type PrimitiveBlockType = PBVerbatim | PBOrdinary | PBParagraph It describes the type of block \u2014 unnamed, environment like \"theorem\" in which the body of the block is parsed, or environment like \"equation\" where it is passed verbatim to the renderer. The status field has type type Status = Finished | Started | Filled It is used in parsing source text into blocks and is needed to handle nested blocks. Lists of lines of text are parsed into lists of primitive blocks by the function -- Parser.PrimitiveLaTeXBlock parse : List String -> List PrimitiveLaTeXBlock parse lines = lines |> parseLoop |> .blocks The Parser The parser is defined in module Parser.PrimitiveLaTeXBlock by functions parse : List String -> List PrimitiveLaTeXBlock parse lines = lines |> parseLoop |> .blocks and parseLoop : List String -> ParserOutput parseLoop lines = loop (init lines) nextStep |> finalize where type alias ParserOutput = { blocks : List PrimitiveLaTeXBlock , stack : List PrimitiveLaTeXBlock , holdingStack : List PrimitiveLaTeXBlock } The parser operates a functional loop . Transform Module MicroLaTeX.Parser.Transform The purpose of this function is to transform a primitive block like the one coming from a single-line paragraph with text \"\\section{Intro}\" to an ordinary (blockType PBOrdinaryBlock) block with name \"section\", args [\"1\"], and content [\"Introduction\"]. This is to coerce parsed MiniLaTeX source to our standard model. Tests Test parsing of text to a list of primitive blocks: -- MicroLaTeXParserTest primitiveBlockRoundTripTest \"nested environments\" text1 Test the internal language: -- MicroLaTeXParserTest roundTrip1 \"\\\\blue{\\\\italic{abc \\\\strong{def}}}\" Test coercion of MicroLaTeX macros to blocks: -- TransformLaTeXTest test_ \"tags\" (toL0 [ \"\\\\tags{AAA}\" ]) [ \"| tags AAA \" ] -- TransformTest test_ \"transform, args\" (toPrimitiveBlocks \"\\n\\n\\\\section{Intro}\\n\\n\" |> List.map transform |> List.map .args) [ [ \"1\" ] ] where toPrimitiveBlocks = Markup.toPrimitiveBlocks MicroLaTeXLang Command line tools The ./CLI folder contains various CLI tools for testing and benchmarking. All use Albert Dahlin's elm/posix package and can be run using velociraptor (command: vr ). Some examples: vr lxparse lxtest/a1.txt vr rt foo.txt vr bench init 100 bench/harmonic.tex","title":"MicroLaTeX Parser"},{"location":"lx-parser/#microlatex-parser","text":"The MicroLaTeX parser first transforms source into a list of primitive LaTeX blocks, then by mapping the parser for the internal language over this list, into a list of expression blocks.","title":"MicroLaTeX Parser"},{"location":"lx-parser/#primitive-blocks","text":"A primitve LaTeX block is a 13-field record as displayed below. -- Parser.PrimitiveLaTeXBlock type alias PrimitiveLaTeXBlock = { indent : Int , lineNumber : Int , position : Int , level : Int , content : List String , firstLine : String , name : Maybe String , args : List String , properties : Dict String String , sourceText : String , blockType : PrimitiveBlockType , status : Status , error : Maybe PrimitiveBlockError } When the source text is parsed into a list of blocks, it is grouped into lists of strings in the content field. The content is also stored as a string in the sourceText field. This is to facilitate synchronization of source text and rendered text. The source text field is carried into the final syntax tree (forest of expression blocks). Consequently, if a piece source text is selected, the syntax tree can can be searched, the matching element can be located and then used to highlight the corresponding part of the rendered text. The indent field is the number of spaces of indentation of the first line of the block; lineNumber is the line number of the first line of the text in the source string; position is its character position in that string. The level field is the depth of the block in the eventual tree structure. Blocks may be un-named, as in the case of paragraph, or named, in the case of a LaTeX environment. This information is stored in the name field. For example, the name of the block \\begin{theorem} ... \\end{theorem} is Just \"theorem\" The firstline field is the first line of a block, i.e., its header. If the header of a block is \"\\begin{theorem}[Pythagoras]\", then its name is \"theorem\" and args is the list [\"Pythagoras] . If we had \"\\begin{theorem}[Pythagoras, foo:bar]\" (XX) then args is still [\"Pythagoras\"], and properties is a dictionary with one key, \"foo\", whose value is \"bar\". Thus args is a list of unnamed args and properties is a dictionary of key-value pairs derived from the named args. (XX: improve this discussion) The blockType field has type type PrimitiveBlockType = PBVerbatim | PBOrdinary | PBParagraph It describes the type of block \u2014 unnamed, environment like \"theorem\" in which the body of the block is parsed, or environment like \"equation\" where it is passed verbatim to the renderer. The status field has type type Status = Finished | Started | Filled It is used in parsing source text into blocks and is needed to handle nested blocks. Lists of lines of text are parsed into lists of primitive blocks by the function -- Parser.PrimitiveLaTeXBlock parse : List String -> List PrimitiveLaTeXBlock parse lines = lines |> parseLoop |> .blocks","title":"Primitive Blocks"},{"location":"lx-parser/#the-parser","text":"The parser is defined in module Parser.PrimitiveLaTeXBlock by functions parse : List String -> List PrimitiveLaTeXBlock parse lines = lines |> parseLoop |> .blocks and parseLoop : List String -> ParserOutput parseLoop lines = loop (init lines) nextStep |> finalize where type alias ParserOutput = { blocks : List PrimitiveLaTeXBlock , stack : List PrimitiveLaTeXBlock , holdingStack : List PrimitiveLaTeXBlock } The parser operates a functional loop .","title":"The Parser"},{"location":"lx-parser/#transform","text":"Module MicroLaTeX.Parser.Transform The purpose of this function is to transform a primitive block like the one coming from a single-line paragraph with text \"\\section{Intro}\" to an ordinary (blockType PBOrdinaryBlock) block with name \"section\", args [\"1\"], and content [\"Introduction\"]. This is to coerce parsed MiniLaTeX source to our standard model.","title":"Transform"},{"location":"lx-parser/#tests","text":"Test parsing of text to a list of primitive blocks: -- MicroLaTeXParserTest primitiveBlockRoundTripTest \"nested environments\" text1 Test the internal language: -- MicroLaTeXParserTest roundTrip1 \"\\\\blue{\\\\italic{abc \\\\strong{def}}}\" Test coercion of MicroLaTeX macros to blocks: -- TransformLaTeXTest test_ \"tags\" (toL0 [ \"\\\\tags{AAA}\" ]) [ \"| tags AAA \" ] -- TransformTest test_ \"transform, args\" (toPrimitiveBlocks \"\\n\\n\\\\section{Intro}\\n\\n\" |> List.map transform |> List.map .args) [ [ \"1\" ] ] where toPrimitiveBlocks = Markup.toPrimitiveBlocks MicroLaTeXLang","title":"Tests"},{"location":"lx-parser/#command-line-tools","text":"The ./CLI folder contains various CLI tools for testing and benchmarking. All use Albert Dahlin's elm/posix package and can be run using velociraptor (command: vr ). Some examples: vr lxparse lxtest/a1.txt vr rt foo.txt vr bench init 100 bench/harmonic.tex","title":"Command line tools"},{"location":"mkdocs/","text":"Welcome to MkDocs For full documentation visit mkdocs.org . Commands mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit. Project layout mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Mkdocs"},{"location":"mkdocs/#welcome-to-mkdocs","text":"For full documentation visit mkdocs.org .","title":"Welcome to MkDocs"},{"location":"mkdocs/#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit.","title":"Commands"},{"location":"mkdocs/#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"overview/","text":"Overview The Scripta compiler transforms text into Element Msg through a series of stages, as illustrated in the following figure. Break the source text into chunks , namely a list of so-called primitive blocks . Ignoring for the moment the possibility of diff records and differential compilation, parse the content of the primitive blocks, transforming string data into lists of Expr (see Intro, section \"Internal Language\" ) Transform the list of expression blocks into a forest of expression blocks using the indentation structure or, in the case of microLaTeX, the level structure. Walk through the forest of expression blocks, accumulating data on section numbers, the table of contents, cross-references etc, while simultaneously updating the forest of expression blocks where indicated. Use this data to produce a so-called EditRecord , a data structure containing all the information needed to render the original source text into Element MarkupMsg , an Elm representation of Html. Use the Edit Record to produce the final rendered text. Flowchart Parsing the internal language Let us concentrate for the moment on step (2) above, parsing the content of the primitive blocks. We will do this first in the case of \"pure\" L0, a simplified version of L0 described below. All the ideas needed in the general case, including for microLaTeX and XMarkdown are present in this simple case. The parser first tokenizes the input, then consumes the tokens one at a time. To process them, it maintains two data structures: a list of committed expressions and a stack of \"unreduced\" tokens. At each step the parser may either commit the token or push it onto the stack. The stack contents may or may not be reducible to an expression (see XX below for examples). If the stack is reducible, the resulting expression is pushed onto the committed list. If not, the process continues. If the stack is empty after all the tokens have been consumed, the parse is successful. If not, there is an error, and the recovery procedure is called. In rough outline, the procedure is as follows: (a) remove the token at the bottom of the stack and use it to construct an expression indicating the presence and nature of the error; (b) push this expression onto the committed list; (c) restart the parser with the truncated stack as input. In short, error recovery works by pushing an error expression onto the committed list based the state of the stack, then skipping a token and restarting the parser. This procedure is guaranteed to terminate and can also handle multiple errors. Whiile simple, it has proved effective in the case of the three markup languages considered here. The strategy just described is essentially that of a classical shift-reduce parser. The shift operation is the act of taking a token from the input and putting it either on the stack or (as an expression), the committed list. The reduce operation occurs when the stack represents an expression: that expression is pushed onto the committed list and the stack is cleared. Pure L0 An element of pure L0 text is one of the following: a span of pure text, e.g. \"roses are red\" a function element, e.g. [italic roses are red] , consisting of a function name (italic here) and a body, which is a sequence consisting of pure text spans and function elements. a sequence of the above. Function elements can be nested, as in [italic roses [bold are] red \". In this example, \"roses\" and \"red\" are italicized, while \"are\" bold italic. Here is a slightly more complicated example: He said that [italic roses [bold are] red]. Cool! Tokenization Tokens for pure L0 are of the type listed below. The constructors LB and RB refer to left and right brackets. Meta is a meta data field that records the location of the part of the source text corresponding to the token. S stands for String and W stands for white space. type Token = LB Meta | RB Meta | S String Meta As an example, the text \"[italic roses]\" tokenizes as LB, S \"italic\", S \" roses\", RB where we have ignored the Meta component. You can verify this as follows: $ elm repl > import L0.Parser.Token exposing(..) > run \"[italic roses]\" |> List.reverse The second token in full form is S \"italic\" { begin = 1, end = 6, index = 1 } The index refers to the index of the token in the token list. It will be used in error recovery. Reduction of a list of tokens Recall that expressions are of type -- Parser.Expr type Expr = Fun String (List Expr) Meta | Text String Meta | Verbatim String String Meta The token list LB, S \"italic\", S \" roses\", RB represents an expression, namely Fun \"italic\" [S \" roses\"] where again we ignore the metadata. On the other hand, the token list LB, S \"italic\", S \" roses\" is not reducible, since the opening LB is unmatched. See the detailed documentation of the L0 parser to see how the function isReducible : List Symbol -> Bool works.","title":"Overview"},{"location":"overview/#overview","text":"The Scripta compiler transforms text into Element Msg through a series of stages, as illustrated in the following figure. Break the source text into chunks , namely a list of so-called primitive blocks . Ignoring for the moment the possibility of diff records and differential compilation, parse the content of the primitive blocks, transforming string data into lists of Expr (see Intro, section \"Internal Language\" ) Transform the list of expression blocks into a forest of expression blocks using the indentation structure or, in the case of microLaTeX, the level structure. Walk through the forest of expression blocks, accumulating data on section numbers, the table of contents, cross-references etc, while simultaneously updating the forest of expression blocks where indicated. Use this data to produce a so-called EditRecord , a data structure containing all the information needed to render the original source text into Element MarkupMsg , an Elm representation of Html. Use the Edit Record to produce the final rendered text.","title":"Overview"},{"location":"overview/#flowchart","text":"","title":"Flowchart"},{"location":"overview/#parsing-the-internal-language","text":"Let us concentrate for the moment on step (2) above, parsing the content of the primitive blocks. We will do this first in the case of \"pure\" L0, a simplified version of L0 described below. All the ideas needed in the general case, including for microLaTeX and XMarkdown are present in this simple case. The parser first tokenizes the input, then consumes the tokens one at a time. To process them, it maintains two data structures: a list of committed expressions and a stack of \"unreduced\" tokens. At each step the parser may either commit the token or push it onto the stack. The stack contents may or may not be reducible to an expression (see XX below for examples). If the stack is reducible, the resulting expression is pushed onto the committed list. If not, the process continues. If the stack is empty after all the tokens have been consumed, the parse is successful. If not, there is an error, and the recovery procedure is called. In rough outline, the procedure is as follows: (a) remove the token at the bottom of the stack and use it to construct an expression indicating the presence and nature of the error; (b) push this expression onto the committed list; (c) restart the parser with the truncated stack as input. In short, error recovery works by pushing an error expression onto the committed list based the state of the stack, then skipping a token and restarting the parser. This procedure is guaranteed to terminate and can also handle multiple errors. Whiile simple, it has proved effective in the case of the three markup languages considered here. The strategy just described is essentially that of a classical shift-reduce parser. The shift operation is the act of taking a token from the input and putting it either on the stack or (as an expression), the committed list. The reduce operation occurs when the stack represents an expression: that expression is pushed onto the committed list and the stack is cleared.","title":"Parsing the internal language"},{"location":"overview/#pure-l0","text":"An element of pure L0 text is one of the following: a span of pure text, e.g. \"roses are red\" a function element, e.g. [italic roses are red] , consisting of a function name (italic here) and a body, which is a sequence consisting of pure text spans and function elements. a sequence of the above. Function elements can be nested, as in [italic roses [bold are] red \". In this example, \"roses\" and \"red\" are italicized, while \"are\" bold italic. Here is a slightly more complicated example: He said that [italic roses [bold are] red]. Cool!","title":"Pure L0"},{"location":"overview/#tokenization","text":"Tokens for pure L0 are of the type listed below. The constructors LB and RB refer to left and right brackets. Meta is a meta data field that records the location of the part of the source text corresponding to the token. S stands for String and W stands for white space. type Token = LB Meta | RB Meta | S String Meta As an example, the text \"[italic roses]\" tokenizes as LB, S \"italic\", S \" roses\", RB where we have ignored the Meta component. You can verify this as follows: $ elm repl > import L0.Parser.Token exposing(..) > run \"[italic roses]\" |> List.reverse The second token in full form is S \"italic\" { begin = 1, end = 6, index = 1 } The index refers to the index of the token in the token list. It will be used in error recovery.","title":"Tokenization"},{"location":"overview/#reduction-of-a-list-of-tokens","text":"Recall that expressions are of type -- Parser.Expr type Expr = Fun String (List Expr) Meta | Text String Meta | Verbatim String String Meta The token list LB, S \"italic\", S \" roses\", RB represents an expression, namely Fun \"italic\" [S \" roses\"] where again we ignore the metadata. On the other hand, the token list LB, S \"italic\", S \" roses\" is not reducible, since the opening LB is unmatched. See the detailed documentation of the L0 parser to see how the function isReducible : List Symbol -> Bool works.","title":"Reduction of a list of tokens"},{"location":"render/","text":"Rendering render : Int -> Accumulator -> Settings -> ExpressionBlock -> Element MarkupMsg of module Block.Render .","title":"Rendering"},{"location":"render/#rendering","text":"render : Int -> Accumulator -> Settings -> ExpressionBlock -> Element MarkupMsg of module Block.Render .","title":"Rendering"},{"location":"synchronization/","text":"Synchronization Sourcemap The id field of an ExpressionBlock is simply the string version of the line number field of the PrimitiveBlock from which it is derived. The id field is used in rendered-to-source syncrhonization. Namely, when the user clicks on a piece of rendered text, the message SendId id is sent. When this is handled, the corresponding source text is scrolled into view and highlighted. (NOTE: still quite innacurate). In both Scripta.io and Scripta Desktop, the message is passed on to the Codemirror editor, whihc does the scrolling and highlighting. PROBLEM: when source text is edited and differential parsing is used, line numbers after the edited text are not update.","title":"Synchronization"},{"location":"synchronization/#synchronization","text":"","title":"Synchronization"},{"location":"synchronization/#sourcemap","text":"The id field of an ExpressionBlock is simply the string version of the line number field of the PrimitiveBlock from which it is derived. The id field is used in rendered-to-source syncrhonization. Namely, when the user clicks on a piece of rendered text, the message SendId id is sent. When this is handled, the corresponding source text is scrolled into view and highlighted. (NOTE: still quite innacurate). In both Scripta.io and Scripta Desktop, the message is passed on to the Codemirror editor, whihc does the scrolling and highlighting. PROBLEM: when source text is edited and differential parsing is used, line numbers after the edited text are not update.","title":"Sourcemap"},{"location":"tests/","text":"Tests To implement: round-trip tests for microLaTeX using the pretty-printer:","title":"Tests"},{"location":"tests/#tests","text":"To implement: round-trip tests for microLaTeX using the pretty-printer:","title":"Tests"}]}